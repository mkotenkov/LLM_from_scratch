{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from time import time\n",
    "\n",
    "from modules.tokenizer import Tokenizer\n",
    "from modules.transformer import Transformer, TransformerConfig\n",
    "from modules.data import WikipediaTokenizedDataset\n",
    "\n",
    "TEST_EXAMPLE = \"\"\"\n",
    "What is a piece of text? 101. Hello, 102. (1) [2] 567890\n",
    "A text is a passage of words that conveys a set of meanings to the person who is reading it. \n",
    "It’s a body of written work, in various forms and structures, that can be words, phrases and sentences that piece together a passage of written work.\n",
    "To put it as simply as possible, it is a group of words. But it can come in many different forms.\n",
    "A text can be written materials, such as books, magazines, newspapers, or online content. \n",
    "But it can also be other things, those that we may not associate with standard text. \n",
    "Text could be movies, scripts, paintings, songs, political cartoons, advertisements and maps. \n",
    "If we can look at something with words and sentences, explore it, find layers of meaning in it, and draw information and conclusions from it, you’re looking at a text.\"\"\"\n",
    "\n",
    "device = \"mps\"\n",
    "\n",
    "tokenizer = Tokenizer.init_and_load(\"/Users/maksimkoltugin/Dev/huawei_LLM_test_task/weights/tokenizer/tokenizer_15k_10k_uncased.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer.init_and_load(\"/Users/maksimkoltugin/Dev/huawei_LLM_test_task/weights/ckpts/transformer_uncased/ckpt_200.pt\")\n",
    "# transformer = Transformer.init_and_load(\"/Users/maksimkoltugin/Dev/huawei_LLM_test_task/weights/ckpts/transformer_uncased/model_100.pt\")\n",
    "\n",
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London is ,  was\n",
      "in\n",
      "es which\n",
      " on( \n",
      ", and( whichthe\n",
      " in\n",
      "\"  of of, but with this), of,( \n",
      " was in to)2 the. and'\n",
      " to,\n",
      " \n",
      "(\n",
      ", and to s- thes of\n",
      " the was at, and\n",
      " a in as\n",
      " \n",
      " of(\n",
      "  ,i\n",
      ", was  to to to, in, for as<pad>. and from,"
     ]
    }
   ],
   "source": [
    "text = \"London is\"\n",
    "print(text, end=\"\")\n",
    "\n",
    "x = tokenizer.encode(text)\n",
    "x = torch.tensor([x]).to(device)\n",
    "\n",
    "# generate!\n",
    "for i in range(100):\n",
    "    # forward the model to get the logits\n",
    "    with torch.no_grad():\n",
    "        logits = transformer(x) # (B, T, vocab_size)\n",
    "        # take the logits at the last position\n",
    "        logits = logits[:, -1, :] # (B, vocab_size)\n",
    "        # get the probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # do top-k sampling of 50 (huggingface pipeline default)\n",
    "        # topk_probs here becomes (5, 50), topk_indices is (5, 50)\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
    "        # select a token from the top-k probabilities\n",
    "        # note: multinomial does not demand the input to sum to 1\n",
    "        ix = torch.multinomial(topk_probs, 1) # (B, 1)\n",
    "        # gather the corresponding indices\n",
    "        xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
    "        # append to the sequence\n",
    "        x = torch.cat([x, xcol], dim=1)\n",
    "\n",
    "        print(tokenizer.decode([xcol.item()]), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huawei_llm_test_task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
