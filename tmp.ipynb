{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from time import time\n",
    "\n",
    "from modules.tokenizer import Tokenizer\n",
    "from modules.transformer import Transformer, TransformerConfig, SamplingStrategy\n",
    "from modules.data import WikipediaTokenizedDataset\n",
    "\n",
    "TEST_EXAMPLE = \"\"\"\n",
    "What is a piece of text? 101. Hello, 102. (1) [2] 567890\n",
    "A text is a passage of words that conveys a set of meanings to the person who is reading it. \n",
    "It’s a body of written work, in various forms and structures, that can be words, phrases and sentences that piece together a passage of written work.\n",
    "To put it as simply as possible, it is a group of words. But it can come in many different forms.\n",
    "A text can be written materials, such as books, magazines, newspapers, or online content. \n",
    "But it can also be other things, those that we may not associate with standard text. \n",
    "Text could be movies, scripts, paintings, songs, political cartoons, advertisements and maps. \n",
    "If we can look at something with words and sentences, explore it, find layers of meaning in it, and draw information and conclusions from it, you’re looking at a text.\"\"\"\n",
    "\n",
    "device = \"mps\"\n",
    "\n",
    "tokenizer = Tokenizer.init_and_load(\"/Users/maksimkoltugin/Dev/huawei_LLM_test_task/checkpoints/tokenizer/tokenizer_15k_10k_uncased.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer = Transformer.init_and_load(\"/Users/maksimkoltugin/Dev/huawei_LLM_test_task/checkpoints/transformer_uncased/ckpts/ckpt_200.pt\")\n",
    "# transformer = Transformer.init_and_load(\"/Users/maksimkoltugin/Dev/huawei_LLM_test_task/weights/ckpts/transformer_uncased/model_100.pt\")\n",
    "\n",
    "transformer = Transformer()\n",
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 16])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_texts = [\n",
    "    \"What is a piece of text?\",\n",
    "    \"A text is a passage of words that conveys a set of meanings.\",\n",
    "    \"To put it as simply as possible, it is a group of words.\",\n",
    "]\n",
    "\n",
    "ids, mask = tokenizer(list_of_texts)\n",
    "ids = ids.to(device)\n",
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits.shape = torch.Size([3, 15256])\n",
      "new_tokens.shape = torch.Size([3, 1])\n",
      "output.shape = torch.Size([3, 17])\n",
      "logits.shape = torch.Size([3, 15256])\n",
      "new_tokens.shape = torch.Size([3, 1])\n",
      "output.shape = torch.Size([3, 18])\n",
      "logits.shape = torch.Size([3, 15256])\n",
      "new_tokens.shape = torch.Size([3, 1])\n",
      "output.shape = torch.Size([3, 19])\n",
      "logits.shape = torch.Size([3, 15256])\n",
      "new_tokens.shape = torch.Size([3, 1])\n",
      "output.shape = torch.Size([3, 20])\n",
      "logits.shape = torch.Size([3, 15256])\n",
      "new_tokens.shape = torch.Size([3, 1])\n",
      "output.shape = torch.Size([3, 21])\n",
      "logits.shape = torch.Size([3, 15256])\n",
      "new_tokens.shape = torch.Size([3, 1])\n",
      "output.shape = torch.Size([3, 22])\n",
      "logits.shape = torch.Size([3, 15256])\n",
      "new_tokens.shape = torch.Size([3, 1])\n",
      "output.shape = torch.Size([3, 23])\n",
      "logits.shape = torch.Size([3, 15256])\n",
      "new_tokens.shape = torch.Size([3, 1])\n",
      "output.shape = torch.Size([3, 24])\n",
      "logits.shape = torch.Size([3, 15256])\n",
      "new_tokens.shape = torch.Size([3, 1])\n",
      "output.shape = torch.Size([3, 25])\n",
      "logits.shape = torch.Size([3, 15256])\n",
      "new_tokens.shape = torch.Size([3, 1])\n",
      "output.shape = torch.Size([3, 26])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[10075,   336,   257,  6763,   283,  3055,    63,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,   850,   850,  5159, 14287,\n",
       "         14287, 14287, 14287, 14287, 14287, 14287],\n",
       "        [   97,  3055,   336,   257,  9857,   283,  5101,   384, 12112,   115,\n",
       "           257,   953,   283,  2679,   657,    46,   850,   850,  5159, 14287,\n",
       "         14287, 14287, 14287, 14287, 14287, 14287],\n",
       "        [ 1387,  2605,   363,   330,  6246,   330,  3469,    44,   363,   336,\n",
       "           257,   914,   283,  5101,    46,     0,   850,   850, 14287, 14287,\n",
       "         14287, 14287, 14287, 14287, 14287, 14287]], device='mps:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.generate(ids, 10, SamplingStrategy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London is articlebraskapg nothing130 alb crops is rele train� jetsclos described ah photo train rele monica fifa fifacityilianbyarks era permittedretdef bast patriculation cu alb poly guerr permittedret zojonevenancheonge referredanche oblig multi multi santi multi monicaterm defeating lanc away secured1684 monica jetsmant electricity seizedclos guerr era mainepert trainretviapertsome ward zo ward stamp diveristerverse movements indie stamp guerr notice operating funeral inher kiret guerrcity guerrкvelop tackle estimated(\" estimatedby prak"
     ]
    }
   ],
   "source": [
    "text = \"London is\"\n",
    "print(text, end=\"\")\n",
    "\n",
    "x = tokenizer.encode(text)\n",
    "x = torch.tensor([x]).to(device)\n",
    "\n",
    "# generate!\n",
    "for i in range(100):\n",
    "    # forward the model to get the logits\n",
    "    with torch.no_grad():\n",
    "        logits = transformer(x) # (B, T, vocab_size)\n",
    "        # take the logits at the last position\n",
    "        logits = logits[:, -1, :] # (B, vocab_size)\n",
    "        # get the probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # do top-k sampling of 50 (huggingface pipeline default)\n",
    "        # topk_probs here becomes (5, 50), topk_indices is (5, 50)\n",
    "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
    "        # select a token from the top-k probabilities\n",
    "        # note: multinomial does not demand the input to sum to 1\n",
    "        ix = torch.multinomial(topk_probs, 1) # (B, 1)\n",
    "        # gather the corresponding indices\n",
    "        xcol = torch.gather(topk_indices, -1, ix) # (B, 1)\n",
    "        # append to the sequence\n",
    "        x = torch.cat([x, xcol], dim=1)\n",
    "\n",
    "        print(tokenizer.decode([xcol.item()]), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huawei_llm_test_task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
